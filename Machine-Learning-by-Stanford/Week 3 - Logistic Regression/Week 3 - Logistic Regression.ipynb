{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88942d76-5ae0-4a09-aee4-908ea6e69101",
   "metadata": {},
   "source": [
    "# Machine Learning: Week 3 - Logistic Regression\n",
    "## Logistic Regression\n",
    "Now we are switching from regression problems to classification problems. Don’t be confused by the name “Logistic Regression”; it is named that way for historical reasons and is actually an approach to classification problems, not regression problems.\n",
    "\n",
    "## Classification\n",
    "Instead of our output vector y being a continuous range of values, it will only be 0 or 1.\n",
    "\n",
    "$$\\large\n",
    "y\\in \\{0,1\\}\n",
    "$$\n",
    "\n",
    "Where $0$ is usually taken as the **“negative class”** and $1$ as the **“positive class”**, but you are free to assign any representation to it.\n",
    "\n",
    "We’re only doing two classes for now, called a _**“Binary Classification Problem”**_.\n",
    "\n",
    "One method is to use linear regression and map all predictions greater than 0.5 as a 1 and all less than 0.5 as a 0. This method doesn’t work well because classification is not actually a linear function.\n",
    "\n",
    "For instance, if we are trying to build a spam classifier for email, then $x^{(i)}$ may be some features of a piece of email, and $y$ may be $1$ if it is a piece of spam mail, and $0$ otherwise. Hence, $y\\in \\{0,1\\}$. $0$ is called the negative class, and 1 the positive class, and they are sometimes also denoted by the symbols “-” and “+.” Given $x^{(i)}$, the corresponding $y^{(i)}$ is also called the label for the training example.\n",
    "\n",
    "\n",
    "## Hypothesis Representation\n",
    "Our hypothesis should satisfy:\n",
    "\n",
    "$$\\large\n",
    "0\\leqslant h_\\theta(x) \\leqslant 1\n",
    "$$\n",
    "\n",
    "Our new form uses the **“Sigmoid Function”**, also called the **“Logistic Function”:**\n",
    "\n",
    "![sigmoidFunction](./Week3_Images/SigmoidFunction.png)\n",
    "\n",
    "The function $g(z)$, shown here, maps any real number to the $(0, 1)$ interval, making it useful for transforming an arbitrary-valued function into a function better suited for classification. Try playing with an interactive plot of sigmoid function: (https://www.desmos.com/calculator/bgontvxotm).\n",
    "\n",
    "We start with our old hypothesis (linear regression), except that we want to restrict the range to $0$ and $1$. This is accomplished by plugging $\\theta^Tx$ into the Logistic Function.\n",
    "\n",
    "$h_\\theta(x)$ will give us the probability that our output is $1$. For example, $h_\\theta(x)=0.7$ gives us the probability of $70\\%$ that our output is $1$.\n",
    "\n",
    "$$\\large\n",
    " \\begin{array}{l}\n",
    "h_{\\theta }( x) =P( y=1|x;\\theta ) =1−P( y=0|x;\\theta )\\\\\n",
    "\\\\\n",
    "\\ P( y=0|x;\\theta ) +P( y=1|x;\\theta ) =1\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "## Decision Boundary\n",
    "In order to get our discrete 0 or 1 classification, we can translate the output of the hypothesis function as follows:\n",
    "\n",
    "$$\\large\n",
    " \\begin{array}{l}\n",
    "h_{\\theta }( x) \\geqslant 0.5\\rightarrow y=1\\\\\n",
    "h_{\\theta }( x) \\ < 0.5\\rightarrow y=0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The way our logistic function g behaves is that when its input is greater than or equal to zero, its output is greater than or equal to 0.5:\n",
    "\n",
    "$$\\large\n",
    " \\begin{array}{l}\n",
    "g( z) \\geqslant 0.5\\\\\n",
    "when\\ z\\geqslant 0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Remember:\n",
    "\n",
    "$$\\large\n",
    "\\begin{array}{l}\n",
    "z=0,\\ e^{0} =1\\Longrightarrow g( z) =\\frac{1}{2}\\\\\n",
    "\\\\\n",
    "z\\rightarrow \\infty ,e^{-\\infty }\\rightarrow 0\\Longrightarrow g( z) =1\\\\\n",
    "\\\\\n",
    "z\\rightarrow -\\infty ,\\ e^{\\infty }\\rightarrow \\infty \\Longrightarrow g( z) =0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "So if our input to $g$ is $\\theta^TX$, then that means:\n",
    "\n",
    "$$\\large\n",
    " \\begin{array}{l}\n",
    "h_{\\theta }( x) \\ =\\ g\\left( \\theta ^{T} X\\right) \\geqslant 0.5\\\\\n",
    "when\\ \\theta ^{T} X\\geqslant 0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "From these statements we can now say:\n",
    "\n",
    "$$\\large\n",
    " \\begin{array}{l}\n",
    "\\theta ^{T} X\\geqslant 0\\Longrightarrow y=1\\ \\\\\n",
    "\\theta ^{T} X< 0\\Longrightarrow y=0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The decision boundary is the line that separates the area where $y = 0$ and where $y = 1$. It is created by our hypothesis function.\n",
    "\n",
    "Example:\n",
    "\n",
    "$$\\large\n",
    "\\begin{array}{l}\n",
    "\\theta =\\begin{bmatrix}\n",
    "5\\\\\n",
    "-1\\\\\n",
    "0\n",
    "\\end{bmatrix}\\\\\n",
    "h_{\\theta }( x) =\\theta _{0} +\\theta _{1} x_{1} +\\theta _{2} x_{2} +...+\\theta _{n} x_{n}\\\\\n",
    "y=1\\ if\\ 5+( -1) x_{1} +0x_{2} \\geqslant 0\\\\\n",
    "5-x_{1} \\geqslant 0\\\\\n",
    "-x_{1} \\geqslant -5\\\\\n",
    "x_{1} \\leqslant 5\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "In this case, our decision boundary is a straight vertical line placed on the graph where $x1 = 5$, and everything to the left of that denotes $y = 1$, while everything to the right denotes $y = 0$.\n",
    "\n",
    "Again, the input to the sigmoid function $g(z)$ (e.g. $\\theta^TX$) doesn’t need to be linear, and could be a function that describes a circle (e.g. $z=\\theta_0+\\theta_1x^{2}_1+\\theta_2x^{2}_2$) or any shape to fit our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7961108-d72b-4487-9ebc-ec847b1e9413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93406ca-c35c-408f-9448-4a22a6e8207b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
